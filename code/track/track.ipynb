{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d13f12fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "from pprint import pprint\n",
    "from dateutil.parser import parse\n",
    "import glob,os\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.patches as patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de99d2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "colormaps = {'red':'#FF2B19', 'orange':'#FFAC19', 'yellow':'#FFFF99', 'light blue':'#00BFFF',\n",
    "             'green':'#0DFF76', 'blue':'#0D80FF', 'cyan':'#00FFFF', 'purple':'#840DFF'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "169b7150",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aiia/newDisk/anaconda3/envs/zz_pytorch/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "\n",
    "#定义UNet模型\n",
    "class DoubleConvolution(nn.Module):\n",
    "    \"\"\"\n",
    "    ### Two $3 \\times 3$ Convolution Layers\n",
    "    Each step in the contraction path and expansive path have two $3 \\times 3$\n",
    "    convolutional layers followed by ReLU activations.\n",
    "    In the U-Net paper they used $0$ padding,\n",
    "    but we use $1$ padding so that final feature map is not cropped.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels: int, out_channels: int):\n",
    "        \"\"\"\n",
    "        :param in_channels: is the number of input channels\n",
    "        :param out_channels: is the number of output channels\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # First $3 \\times 3$ convolutional layer\n",
    "        self.first = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.act1 = nn.LeakyReLU(LkReLU_num)\n",
    "        # Second $3 \\times 3$ convolutional layer\n",
    "        self.second = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.act2 = nn.LeakyReLU(LkReLU_num)\n",
    "        # Dropout\n",
    "        self.drop = nn.Dropout(Drop_num)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        # Apply the two convolution layers and activations\n",
    "        x = self.first(x)\n",
    "        x = self.act1(x)\n",
    "        \n",
    "        x = self.second(x)\n",
    "        x = self.act2(x)\n",
    "\n",
    "        x = self.drop(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class DownSample(nn.Module):\n",
    "    \"\"\"\n",
    "    ### Down-sample\n",
    "    Each step in the contracting path down-samples the feature map with\n",
    "    a $2 \\times 2$ max pooling layer.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Max pooling layer\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        return self.pool(x)\n",
    "\n",
    "\n",
    "class UpSample(nn.Module):\n",
    "    \"\"\"\n",
    "    ### Up-sample\n",
    "    Each step in the expansive path up-samples the feature map with\n",
    "    a $2 \\times 2$ up-convolution.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels: int, out_channels: int):\n",
    "        super().__init__()\n",
    "\n",
    "        # Up-convolution\n",
    "        self.up = nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        return self.up(x)\n",
    "\n",
    "\n",
    "class CropAndConcat(nn.Module):\n",
    "    \"\"\"\n",
    "    ### Crop and Concatenate the feature map\n",
    "    At every step in the expansive path the corresponding feature map from the contracting path\n",
    "    concatenated with the current feature map.\n",
    "    \"\"\"\n",
    "    def forward(self, x: torch.Tensor, contracting_x: torch.Tensor):\n",
    "        \"\"\"\n",
    "        :param x: current feature map in the expansive path\n",
    "        :param contracting_x: corresponding feature map from the contracting path\n",
    "        \"\"\"\n",
    "\n",
    "        # Crop the feature map from the contracting path to the size of the current feature map\n",
    "        contracting_x = transforms.functional.center_crop(contracting_x, [x.shape[2], x.shape[3]])\n",
    "        # Concatenate the feature maps\n",
    "        x = torch.cat([x, contracting_x], dim=1)\n",
    "        #\n",
    "        return x\n",
    "\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    \"\"\"\n",
    "    ## U-Net\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels: int, out_channels: int):\n",
    "        \"\"\"\n",
    "        :param in_channels: number of channels in the input image\n",
    "        :param out_channels: number of channels in the result feature map\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # Double convolution layers for the contracting path.\n",
    "        # The number of features gets doubled at each step starting from $64$.\n",
    "        self.down_conv = nn.ModuleList([DoubleConvolution(i, o) for i, o in\n",
    "                                        [(in_channels, 64), (64, 128), (128, 256), (256, 512)]])\n",
    "        # Down sampling layers for the contracting path\n",
    "        self.down_sample = nn.ModuleList([DownSample() for _ in range(4)])\n",
    "\n",
    "        # The two convolution layers at the lowest resolution (the bottom of the U).\n",
    "        self.middle_conv = DoubleConvolution(512, 1024)\n",
    "\n",
    "        # Up sampling layers for the expansive path.\n",
    "        # The number of features is halved with up-sampling.\n",
    "        self.up_sample = nn.ModuleList([UpSample(i, o) for i, o in\n",
    "                                        [(1024, 512), (512, 256), (256, 128), (128, 64)]])\n",
    "        # Double convolution layers for the expansive path.\n",
    "        # Their input is the concatenation of the current feature map and the feature map from the\n",
    "        # contracting path. Therefore, the number of input features is double the number of features\n",
    "        # from up-sampling.\n",
    "        self.up_conv = nn.ModuleList([DoubleConvolution(i, o) for i, o in\n",
    "                                      [(1024, 512), (512, 256), (256, 128), (128, 64)]])\n",
    "        # Crop and concatenate layers for the expansive path.\n",
    "        self.concat = nn.ModuleList([CropAndConcat() for _ in range(4)])\n",
    "        # Final $1 \\times 1$ convolution layer to produce the output\n",
    "        self.final_conv = nn.Conv2d(64, out_channels, kernel_size=1)\n",
    "        #activation\n",
    "        self.activation = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        \"\"\"\n",
    "        :param x: input image\n",
    "        \"\"\"\n",
    "        # To collect the outputs of contracting path for later concatenation with the expansive path.\n",
    "        pass_through = []\n",
    "        # Contracting path\n",
    "        for i in range(len(self.down_conv)):\n",
    "            # Two $3 \\times 3$ convolutional layers\n",
    "            x = self.down_conv[i](x)\n",
    "            # Collect the output\n",
    "            pass_through.append(x)\n",
    "            # Down-sample\n",
    "            x = self.down_sample[i](x)\n",
    "\n",
    "        # Two $3 \\times 3$ convolutional layers at the bottom of the U-Net\n",
    "        x = self.middle_conv(x)\n",
    "\n",
    "        # Expansive path\n",
    "        for i in range(len(self.up_conv)):\n",
    "            # Up-sample\n",
    "            x = self.up_sample[i](x)\n",
    "            # Concatenate the output of the contracting path\n",
    "            x = self.concat[i](x, pass_through.pop())\n",
    "            # Two $3 \\times 3$ convolutional layers\n",
    "            x = self.up_conv[i](x)\n",
    "            \n",
    "        # Final $1 \\times 1$ convolution layer\n",
    "        x = self.final_conv(x)\n",
    "\n",
    "        #activation\n",
    "        x = self.activation(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97772a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#unet模型输入输出数据预处理\n",
    "def input_process(file):\n",
    "    if isinstance(file, str):\n",
    "        try:\n",
    "            img = Image.open(file).convert('L')\n",
    "        except:\n",
    "            try:\n",
    "                hdu_data, hdu_header = readchase(file)\n",
    "                img = hdu_data[68]\n",
    "            except:\n",
    "                hdu_data, hdu_header = fits.open(file)\n",
    "                img = hdu_data\n",
    "    elif isinstance(file, np.ndarray):\n",
    "        img = file\n",
    "    else:\n",
    "        raise TypeError('can not recognize file type, only image, fits and numpy.ndarray are supported')\n",
    "\n",
    "    if img.max() <= 0:\n",
    "        raise ValueError('image\\'s max value is 0')\n",
    "    elif img.shape != (2048,2048):\n",
    "        raise ValueError(f'image\\'s shape is {img.shape}, not adaptive')\n",
    "    \n",
    "    img = img / img.mean()\n",
    "        \n",
    "    return transforms.ToTensor()(img).unsqueeze(0).to(device=device, dtype=torch.float32)\n",
    "\n",
    "def output_process(output):\n",
    "    output = (output >= 0.5)*1\n",
    "    return output\n",
    "        \n",
    "def model_predict(model, input_img):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(input_img)\n",
    "    \n",
    "    return output.cpu().squeeze().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7159438",
   "metadata": {},
   "outputs": [],
   "source": [
    "#读取文件\n",
    "def readchase(file):\n",
    "    from astropy.io import fits\n",
    "    hdu = fits.open(file)\n",
    "    try:\n",
    "        data = hdu[0].data.astype(np.float32)\n",
    "        header = hdu[0].header\n",
    "        \n",
    "    except:\n",
    "        header = hdu[1].header\n",
    "        data = hdu[1].data\n",
    "        \n",
    "    if len(data.shape) != 3:\n",
    "        raise TypeError('file ', str(file), 'is not Chase\\'s file, please use other function to read.')\n",
    "     \n",
    "    hdu_time = datetime.strptime(header['DATE_OBS'], \"%Y-%m-%dT%H:%M:%S\")\n",
    "    if hdu_time < datetime.strptime('2023-04-18', \"%Y-%m-%d\"):\n",
    "        cy = header['CRPIX1']\n",
    "        cx = header['CRPIX2']\n",
    "    else:\n",
    "        cx = header['CRPIX1']\n",
    "        cy = header['CRPIX2']\n",
    "\n",
    "    #改变数组大小、日心位置\n",
    "    data = data[:, int(cy-1023):int(cy+1025), int(cx-1023):int(cx+1025)]\n",
    "    if data.shape != (118,2048,2048):\n",
    "        raise TypeError('Chase file ', file, 'is corrupted, please check.')\n",
    "    \n",
    "    cx = 1023 + cx - int(cx)\n",
    "    cy = 1023 + cy - int(cy)\n",
    "    header['CRPIX1'] = 1023 + cx - int(cx)\n",
    "    header['CRPIX2'] = 1023 + cy - int(cy)\n",
    "    header['NAXIS1'] = 2048\n",
    "    header['NAXIS2'] = 2048\n",
    "    \n",
    "    return data, header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "809ebc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#图像处理：标记\n",
    "def get_labels(loc, result):\n",
    "    img = np.zeros(shape = (2048,2048))\n",
    "    for i in range(loc.shape[0]):\n",
    "        x,y = loc[i]\n",
    "        img[x,y] = result[i]\n",
    "    \n",
    "    return np.array(img)\n",
    "\n",
    "def mark_connection(img, min_distance=1.5):\n",
    "    loc = np.array(img.nonzero()).T\n",
    "\n",
    "    from sklearn.cluster import DBSCAN\n",
    "    dmodel = DBSCAN(eps = min_distance, min_samples= 2)\n",
    "    dmodel.fit(loc)\n",
    "    dresult = dmodel.labels_ + 1\n",
    "    \n",
    "    labels = get_labels(loc, dresult)\n",
    "    \n",
    "    return labels\n",
    "\n",
    "def select_img(labels, min_size):\n",
    "    img = (labels > 0)*1\n",
    "    N = int(labels.max())\n",
    "    #print(N)\n",
    "    from scipy.ndimage import labeled_comprehension\n",
    "    labelsum = labeled_comprehension(img, labels,index = np.arange(1,N+1), func =  sum, out_dtype = int, default = 0)\n",
    "    #print(labelsum.shape ,labelsum.max())\n",
    "    j = 1\n",
    "    nimg = np.zeros(shape = img.shape)\n",
    "    for i in range(N):\n",
    "        if labelsum[i] >= min_size:\n",
    "            nimg = nimg + (labels == i+1)*j\n",
    "            j = j + 1\n",
    "            \n",
    "    return nimg\n",
    "\n",
    "def select_filament(img, min_distance = 10, min_size = 100):\n",
    "    label_filament = mark_connection(img)\n",
    "    img_filament = select_img(label_filament, min_size = 10)\n",
    "    label_filament = mark_connection((img_filament>0)*1, min_distance)\n",
    "    img_filament = select_img(label_filament, min_size)\n",
    "    \n",
    "    return (img_filament > 0)*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a55a355d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#boxes匹配\n",
    "def calculate_iou(box1, box2):\n",
    "    \"\"\"\n",
    "    计算两个矩形框的IOU（Intersection over Union）\n",
    "    \n",
    "    参数：\n",
    "    box1: 第一个矩形框的坐标，格式为 (x1, y1, w1, h1)\n",
    "    box2: 第二个矩形框的坐标，格式为 (x2, y2, w2, h2)\n",
    "    \n",
    "    返回：\n",
    "    iou: 两个矩形框的IOU值\n",
    "    \"\"\"\n",
    "    x1, y1, w1, h1 = box1\n",
    "    x2, y2, w2, h2 = box2\n",
    "    \n",
    "    # 计算相交矩形框的左上角和右下角坐标\n",
    "    inter_x1 = max(x1, x2)\n",
    "    inter_y1 = max(y1, y2)\n",
    "    inter_x2 = min(x1 + w1, x2 + w2)\n",
    "    inter_y2 = min(y1 + h1, y2 + h2)\n",
    "    \n",
    "    # 计算相交矩形框的面积\n",
    "    intersection_area = max(0, inter_x2 - inter_x1) * max(0, inter_y2 - inter_y1)\n",
    "    \n",
    "    # 计算并集矩形框的面积\n",
    "    box1_area = w1 * h1\n",
    "    box2_area = w2 * h2\n",
    "    union_area = box1_area + box2_area - intersection_area\n",
    "    \n",
    "    # 计算IOU\n",
    "    iou = intersection_area / union_area\n",
    "    \n",
    "    return iou\n",
    "\n",
    "def calculate_recall(box1, box2):\n",
    "    \"\"\"\n",
    "    计算两个矩形框的IOU（Intersection over Union）\n",
    "    \n",
    "    参数：\n",
    "    box1: 第一个矩形框的坐标，格式为 (x1, y1, w1, h1)\n",
    "    box2: 第二个矩形框的坐标，格式为 (x2, y2, w2, h2)\n",
    "    \n",
    "    返回：\n",
    "    iou: 两个矩形框的IOU值\n",
    "    \"\"\"\n",
    "    x1, y1, w1, h1 = box1\n",
    "    x2, y2, w2, h2 = box2\n",
    "    \n",
    "    # 计算相交矩形框的左上角和右下角坐标\n",
    "    inter_x1 = max(x1, x2)\n",
    "    inter_y1 = max(y1, y2)\n",
    "    inter_x2 = min(x1 + w1, x2 + w2)\n",
    "    inter_y2 = min(y1 + h1, y2 + h2)\n",
    "    \n",
    "    # 计算相交矩形框的面积\n",
    "    intersection_area = max(0, inter_x2 - inter_x1) * max(0, inter_y2 - inter_y1)\n",
    "    \n",
    "    # 计算并集矩形框的面积\n",
    "    box2_area = w2 * h2\n",
    "    \n",
    "    # 计算IOU\n",
    "    recall = intersection_area / box2_area\n",
    "    \n",
    "    return recall\n",
    "\n",
    "def match_boxes(boxes1, boxes2):\n",
    "    \"\"\"\n",
    "    对两批框子进行一一对应，根据IOU大小确定对应关系\n",
    "    \n",
    "    参数：\n",
    "    boxes1: 第一批框子的列表，每个框子的坐标格式为 (x1, y1, w1, h1)\n",
    "    boxes2: 第二批框子的列表，每个框子的坐标格式为 (x2, y2, w2, h2)\n",
    "    \n",
    "    返回：\n",
    "    matches: 一个列表，包含对应关系的元组，每个元组格式为 (box1_index, box2_index)\n",
    "    \"\"\"\n",
    "    matches = []\n",
    "    \n",
    "    for i, box1 in enumerate(boxes1):\n",
    "        best_iou = 0\n",
    "        best_match_index = -1\n",
    "        \n",
    "        for j, box2 in enumerate(boxes2):\n",
    "            iou = calculate_iou(box1, box2)\n",
    "            \n",
    "            if iou > best_iou:\n",
    "                best_iou = iou\n",
    "                best_match_index = j\n",
    "        \n",
    "        matches.append((i, best_match_index))\n",
    "    \n",
    "    return matches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6be988c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model using cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "UNet(\n",
       "  (down_conv): ModuleList(\n",
       "    (0): DoubleConvolution(\n",
       "      (first): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (act1): LeakyReLU(negative_slope=0.1)\n",
       "      (second): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (act2): LeakyReLU(negative_slope=0.1)\n",
       "      (drop): Dropout(p=0.2, inplace=False)\n",
       "    )\n",
       "    (1): DoubleConvolution(\n",
       "      (first): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (act1): LeakyReLU(negative_slope=0.1)\n",
       "      (second): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (act2): LeakyReLU(negative_slope=0.1)\n",
       "      (drop): Dropout(p=0.2, inplace=False)\n",
       "    )\n",
       "    (2): DoubleConvolution(\n",
       "      (first): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (act1): LeakyReLU(negative_slope=0.1)\n",
       "      (second): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (act2): LeakyReLU(negative_slope=0.1)\n",
       "      (drop): Dropout(p=0.2, inplace=False)\n",
       "    )\n",
       "    (3): DoubleConvolution(\n",
       "      (first): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (act1): LeakyReLU(negative_slope=0.1)\n",
       "      (second): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (act2): LeakyReLU(negative_slope=0.1)\n",
       "      (drop): Dropout(p=0.2, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (down_sample): ModuleList(\n",
       "    (0): DownSample(\n",
       "      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (1): DownSample(\n",
       "      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (2): DownSample(\n",
       "      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "    (3): DownSample(\n",
       "      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    )\n",
       "  )\n",
       "  (middle_conv): DoubleConvolution(\n",
       "    (first): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (act1): LeakyReLU(negative_slope=0.1)\n",
       "    (second): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (act2): LeakyReLU(negative_slope=0.1)\n",
       "    (drop): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       "  (up_sample): ModuleList(\n",
       "    (0): UpSample(\n",
       "      (up): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2))\n",
       "    )\n",
       "    (1): UpSample(\n",
       "      (up): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "    )\n",
       "    (2): UpSample(\n",
       "      (up): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
       "    )\n",
       "    (3): UpSample(\n",
       "      (up): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "    )\n",
       "  )\n",
       "  (up_conv): ModuleList(\n",
       "    (0): DoubleConvolution(\n",
       "      (first): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (act1): LeakyReLU(negative_slope=0.1)\n",
       "      (second): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (act2): LeakyReLU(negative_slope=0.1)\n",
       "      (drop): Dropout(p=0.2, inplace=False)\n",
       "    )\n",
       "    (1): DoubleConvolution(\n",
       "      (first): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (act1): LeakyReLU(negative_slope=0.1)\n",
       "      (second): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (act2): LeakyReLU(negative_slope=0.1)\n",
       "      (drop): Dropout(p=0.2, inplace=False)\n",
       "    )\n",
       "    (2): DoubleConvolution(\n",
       "      (first): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (act1): LeakyReLU(negative_slope=0.1)\n",
       "      (second): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (act2): LeakyReLU(negative_slope=0.1)\n",
       "      (drop): Dropout(p=0.2, inplace=False)\n",
       "    )\n",
       "    (3): DoubleConvolution(\n",
       "      (first): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (act1): LeakyReLU(negative_slope=0.1)\n",
       "      (second): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (act2): LeakyReLU(negative_slope=0.1)\n",
       "      (drop): Dropout(p=0.2, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (concat): ModuleList(\n",
       "    (0): CropAndConcat()\n",
       "    (1): CropAndConcat()\n",
       "    (2): CropAndConcat()\n",
       "    (3): CropAndConcat()\n",
       "  )\n",
       "  (final_conv): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (activation): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#U-Net模型导入\n",
    "Drop_num = 0.2\n",
    "LkReLU_num = 0.1\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.set_device(0)\n",
    "    \n",
    "print('model using', device)\n",
    "    \n",
    "model = UNet(1,1)\n",
    "model.load_state_dict(torch.load('./model/unet_model.pth', map_location=device))\n",
    "\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0c928a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 一些参数定义\n",
    "HA_save_path = './results/ha/'\n",
    "flt_save_path = './results/filament/'\n",
    "track_save_path = './results/track/'\n",
    "\n",
    "case_distance = 50\n",
    "case_size = 200\n",
    "\n",
    "#初始化暗条信息数据\n",
    "filament_info = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16e9e59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#构造多目标追踪器\n",
    "import cv2\n",
    "# （1）参数设置（指定追踪器类型）\n",
    "OPENCV_OBJECT_TRACKERS = {\n",
    "    \"csrt\": cv2.legacy.TrackerCSRT_create,\n",
    "    \"kcf\": cv2.legacy.TrackerKCF_create,\n",
    "    \"boosting\": cv2.legacy.TrackerBoosting_create,\n",
    "    \"mil\": cv2.legacy.TrackerMIL_create,\n",
    "    \"tld\": cv2.legacy.TrackerTLD_create,\n",
    "    \"medianflow\": cv2.legacy.TrackerMedianFlow_create,\n",
    "    \"mosse\": cv2.legacy.TrackerMOSSE_create\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf3e9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "track_file_path = '/data/track_file/'\n",
    "\n",
    "for month in range(11):\n",
    "    month_file_path = track_file_path + f'{month}/'\n",
    "    month_file_list = glob.glob(os.path.join(month_file_path, \"*HA.fits\"))\n",
    "    month_file_list.sort()\n",
    "    print(f'month {month} has {len(month_file_list)} files')\n",
    "    \n",
    "    #创建子文件夹保存结果\n",
    "    sub_HA_path = HA_save_path + f'{month}/'\n",
    "    sub_flt_path = flt_save_path + f'{month}/'\n",
    "    sub_track_path = track_save_path + f'{month}/'\n",
    "\n",
    "    if not os.path.exists(sub_HA_path):\n",
    "        os.makedirs(sub_HA_path)\n",
    "    if not os.path.exists(sub_flt_path):\n",
    "        os.makedirs(sub_flt_path)\n",
    "    if not os.path.exists(sub_track_path):\n",
    "        os.makedirs(sub_track_path)\n",
    "        \n",
    "    j=1\n",
    "    for hdu_file in month_file_list:\n",
    "        #读取数据\n",
    "        try:\n",
    "            hdu_data, hdu_header = readchase(hdu_file)\n",
    "            #文件信息\n",
    "            hdu_HA = hdu_data[69]\n",
    "            hdu_time = parse(hdu_header['DATE_OBS'])\n",
    "            image_name = hdu_time.strftime(\"%m%d_%H%M\")\n",
    "            #Unet模型预测\n",
    "            hdu_input = input_process(hdu_HA)\n",
    "            hdu_output = model_predict(model, hdu_input)\n",
    "            hdu_output = output_process(hdu_output).astype('uint8')\n",
    "\n",
    "            plt.imsave(sub_HA_path + f'HA_{image_name}.png',hdu_HA, vmin=0, vmax=hdu_HA.mean()*3, cmap='afmhot', origin='lower')\n",
    "            plt.imsave(sub_flt_path + f'flt_{image_name}.png', hdu_output, vmin=0, vmax=1 ,cmap='gray', origin='lower')\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "        #对第一个文件的处理\n",
    "        if j==1:\n",
    "            #初始化跟踪器，边界框，暗条id\n",
    "            filament_id_counter = 0\n",
    "            boxes = []\n",
    "            trackers = cv2.legacy.MultiTracker_create()\n",
    "            \n",
    "            primary_HA = hdu_HA\n",
    "            primary_flt = hdu_output\n",
    "            \n",
    "            primary_slt = select_filament(primary_flt, case_distance, case_size)\n",
    "            primary_mark = mark_connection(primary_slt, case_distance)\n",
    "            primary_filament_num = int(primary_mark.max() + 1)\n",
    "            primary_time = hdu_time\n",
    "            primary_date = primary_time.strftime('%Y-%m%d')\n",
    "            \n",
    "            for k in range(1, primary_filament_num):\n",
    "                filament_id_counter += 1\n",
    "                filament_id = f\"{month}-{filament_id_counter}\"\n",
    "                \n",
    "                index = np.where(primary_mark == k)\n",
    "                x = index[1].min() -10 \n",
    "                x_ = index[1].max() +10\n",
    "                y = index[0].min() -10\n",
    "                y_ = index[0].max() +10\n",
    "                boxes.append([x, y, x_-x, y_-y, filament_id])\n",
    "\n",
    "                #创建跟踪器\n",
    "                tracker = OPENCV_OBJECT_TRACKERS['csrt']()\n",
    "                trackers.add(tracker, primary_flt*255, [x,y,x_-x,y_-y])\n",
    "\n",
    "                filament_info[filament_id] = {'id':filament_id, 'observed':str(primary_time), 'disappeared':False}\n",
    "                \n",
    "            #可视化结果\n",
    "            fig, ax = plt.subplots(figsize = (24,24))\n",
    "            plt.imshow(primary_HA, vmin = 0, vmax = primary_HA.mean()*3, cmap = 'gray', origin = 'lower')\n",
    "            #ax.contour(primary_mark, linewidths = 0.5, colors = 'green')\n",
    "            for box in boxes:\n",
    "                x,y,w,h = box[:4]\n",
    "                rect = plt.Rectangle((x, y), w, h,\n",
    "                                     linewidth=5, edgecolor=colormaps['orange'], facecolor='none')\n",
    "                ax.add_patch(rect)\n",
    "\n",
    "                # 添加矩形框标签\n",
    "                label_x = x + w/2\n",
    "                label_y = y + h \n",
    "                ax.text(label_x, label_y, box[4], fontsize=48, ha='center', va='bottom', color = colormaps['cyan'])\n",
    "                \n",
    "            ax.text(0.99, 0.01, primary_time.strftime('%Y-%m-%d %H:%M UT'), transform=ax.transAxes,\n",
    "                    fontsize=36, fontweight='bold', color = 'white', horizontalalignment='right')\n",
    "\n",
    "            ax.axis('off')\n",
    "            fig.patch.set_visible(False)\n",
    "            \n",
    "            plt.savefig(sub_track_path+f'track_{image_name}.png', bbox_inches=\"tight\")\n",
    "            plt.show()\n",
    "            print(f'primary image {image_name} has been saved')\n",
    "            \n",
    "            current_date = primary_date\n",
    "            j = 0\n",
    "                \n",
    "        #跟踪\n",
    "        else:\n",
    "            starttime = datetime.now()\n",
    "            #读取新的文件\n",
    "            new_time = hdu_time\n",
    "            new_HA = hdu_HA\n",
    "            new_flt = hdu_output\n",
    "\n",
    "            #标记新图像\n",
    "            new_slt = select_filament(new_flt, case_distance, case_size)\n",
    "            new_mark = mark_connection(new_slt, case_distance)\n",
    "            boxes2 = []\n",
    "            new_filament_num = int(new_mark.max() + 1)\n",
    "            for j in range(1, new_filament_num):\n",
    "                index = np.where(new_mark == j)\n",
    "                x1 = index[1].min() -10 \n",
    "                x2 = index[1].max() +10\n",
    "                y1 = index[0].min() -10\n",
    "                y2 = index[0].max() +10\n",
    "                boxes2.append([x1, y1, x2-x1, y2-y1])\n",
    "            boxes2 = np.array(boxes2)\n",
    "\n",
    "            #目标跟踪\n",
    "            (success, boxes_) = trackers.update(new_slt.astype('uint8')*255)\n",
    "\n",
    "            #print(boxes_)\n",
    "            #可视化结果\n",
    "\n",
    "            #匹配识别结果与新标记结果\n",
    "            matched_pairs = match_boxes(boxes2, boxes_)\n",
    "            matched_pairs = np.array(matched_pairs)\n",
    "\n",
    "            #处理暗条消失：\n",
    "            for j in range(len(boxes_)):\n",
    "                exist = np.isin(j, matched_pairs[:,1])\n",
    "                if not exist:\n",
    "                    disappeared_filament_id = boxes[j][4]\n",
    "                    filament_info[str(disappeared_filament_id)]['disappeared'] = str(new_time)\n",
    "\n",
    "            #更新框\n",
    "            new_boxes = []\n",
    "            match_index = np.array(np.unique(matched_pairs[:,1]))\n",
    "\n",
    "            for j in range(match_index.shape[0]):\n",
    "                #合并框\n",
    "                if match_index[j] != -1:\n",
    "                    box_index = np.where(matched_pairs[:,1] == match_index[j])[0]\n",
    "\n",
    "                    #标记结果\n",
    "                    nx = boxes2[box_index, 0].min()\n",
    "                    ny = boxes2[box_index, 1].min()\n",
    "                    nx_ = (boxes2[box_index, 0] + boxes2[box_index, 2]).max()\n",
    "                    ny_ = (boxes2[box_index, 1] + boxes2[box_index, 3]).max()\n",
    "\n",
    "                    new_boxes.append([int(nx), int(ny), int(nx_-nx), int(ny_-ny), boxes[match_index[j]][4]])\n",
    "                #标记新生暗条标记：\n",
    "                else:\n",
    "                    box_index = np.where(matched_pairs[:,1] == -1)[0]\n",
    "                    for k in range(box_index.shape[0]):\n",
    "                        filament_id_counter += 1\n",
    "                        filament_id = f\"{month}-{filament_id_counter}\"#current_date + \n",
    "                        x, y, w, h = boxes2[box_index[k]]\n",
    "                        new_boxes.append([int(x), int(y), int(w), int(h), filament_id])\n",
    "                        filament_info[filament_id] = {'id':filament_id, 'observed':str(new_time), 'disappeared':False}\n",
    "\n",
    "            \n",
    "            #整理boxes\n",
    "            boxes = sorted(new_boxes, key=lambda x:x[4])\n",
    "\n",
    "            #更新trackers\n",
    "            trackers = cv2.legacy.MultiTracker_create()\n",
    "            for box in boxes:\n",
    "                x,y,w,h = [int(x) for x in box[:4]]\n",
    "                tracker = OPENCV_OBJECT_TRACKERS['csrt']()\n",
    "                trackers.add(tracker, new_flt*255, [x,y,w,h])\n",
    "\n",
    "            #跟踪结果可视化\n",
    "\n",
    "            fig, ax = plt.subplots(figsize = (24,24))\n",
    "\n",
    "            plt.imshow(new_HA, vmin = 0, vmax = new_HA.mean()*3, cmap = 'gray', origin = 'lower')\n",
    "            for box in boxes:\n",
    "                x,y,w,h = box[:4]\n",
    "                rect = plt.Rectangle((x, y), w, h,\n",
    "                                     linewidth=5, edgecolor=colormaps['orange'], facecolor='none')\n",
    "                ax.add_patch(rect)\n",
    "\n",
    "                # 添加矩形框标签\n",
    "                label_x = x\n",
    "                label_y = y + h\n",
    "                ax.text(label_x, label_y, box[4],fontsize=48, ha='center', va='bottom', color = colormaps['cyan'])\n",
    "\n",
    "            ax.text(0.99, 0.01, new_time.strftime('%Y-%m-%d UT %H:%M'), transform=ax.transAxes,\n",
    "                    fontsize=36, fontweight='bold', color = 'white', horizontalalignment='right')\n",
    "\n",
    "            ax.axis('off')\n",
    "            fig.patch.set_visible(False)\n",
    "\n",
    "            plt.savefig(sub_track_path+f'track_{image_name}.png', bbox_inches=\"tight\")\n",
    "            plt.show()\n",
    "\n",
    "            endtime = datetime.now()\n",
    "            print(f'track {image_name} costed {(endtime - starttime).total_seconds():.3f} s')\n",
    "        \n",
    "    pprint(filament_info)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faaf6020",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
